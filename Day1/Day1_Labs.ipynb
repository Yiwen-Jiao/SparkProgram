{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day1Labs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-d2B_SWkUr8r",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/class/)\n",
        "from initspark import *\n",
        "sc, spark, conf = initspark()\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MKi0nuXXUr8v"
      },
      "source": [
        "**LAB:** Put the regions folder found in /home/student/ROI/SparkProgram/datasets/northwind/CSV/regions into HDFS. Read it into an RDD and convert it into a tuple shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IIcaEx_MUr8x",
        "colab": {}
      },
      "source": [
        "! hadoop fs -rm -r /regions\n",
        "! hadoop fs -put /class/datasets/northwind/CSV/regions /regions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gQ5lYOFqUr80",
        "colab": {}
      },
      "source": [
        "regions = sc.textFile('hdfs://localhost:9000/regions')\n",
        "regions = regions.map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1]))\n",
        "print(regions.collect())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M1-aKC9mUr88"
      },
      "source": [
        "**LAB:** Try to sort region by name and descending order by ID."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wTzNYHFdUr89",
        "colab": {}
      },
      "source": [
        "print(regions.sortByKey(ascending = False).collect())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "72HbeJeuUr9B",
        "colab": {}
      },
      "source": [
        "print(regions.sortBy(lambda x : x[1]).collect())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eE5Wx0GOUr9F"
      },
      "source": [
        "**LAB:** Load territories into HDFS and join it to regions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hyYTLBa9Ur9G",
        "colab": {}
      },
      "source": [
        "! hadoop fs -rm -r /territories\n",
        "! hadoop fs -put /class/datasets/northwind/CSV/territories /territories\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yGap32NhUr9N",
        "colab": {}
      },
      "source": [
        "territories = sc.textFile('hdfs://localhost:9000/territories')\n",
        "territories = territories.map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1], int(x[2])))\n",
        "print(territories.collect())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eM2-Hwu4Ur9R",
        "colab": {}
      },
      "source": [
        "region_territories = regions.join(territories.map(lambda x : (x[2], (x[0],x[1]))))\n",
        "#print (region_territories.collect())\n",
        "region_territories = region_territories.map(lambda x : (x[0], (x[1][0], *x[1][1])))\n",
        "print(region_territories.collect())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F-LJHqSyUr9U"
      },
      "source": [
        "**LAB:** Use the territories RDD to count how many territories are in each region. Display the results in regionID order and then descending order based on the counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lXn67dU5Ur9W",
        "colab": {}
      },
      "source": [
        "region_count = territories.map(lambda x : (x[2], 1)).reduceByKey(lambda x, y: x + y)\n",
        "print(region_count.sortByKey().collect())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sGSwE3tLUr9f",
        "colab": {}
      },
      "source": [
        "print(region_count.sortBy(lambda x : x[1], ascending = False).collect())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BXygCABOUr9p",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}