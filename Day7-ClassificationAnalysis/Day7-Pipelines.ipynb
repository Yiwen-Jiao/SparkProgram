{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Day7-Pipelines.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU1Y1AWbQ7D4",
        "colab_type": "code",
        "colab": {},
        "outputId": "0fb7bfbe-d5f2-4506-c4ce-71c186dc2d22"
      },
      "source": [
        "import sys\n",
        "\n",
        "rootpath = '/class'\n",
        "datapath = f'{rootpath}/datasets/'\n",
        "sys.path.append(rootpath)\n",
        "import pyspark_helpers as pyh\n",
        "from pyspark_helpers import *\n",
        "sc, spark, conf = initspark()\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib as mp\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from pyspark_helpers import display\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initializing pyspark\n",
            "pyspark initialized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkhdr85WQ7EH",
        "colab_type": "text"
      },
      "source": [
        "### The following helper function shows the building of stages to convert categorical and numeric columns into Vectorized versions using a Pipeline instead of building the steps as a series of DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpKa0_m3Q7EJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MakeMLPipeline(df, categorical_features, numeric_features, target_label = None, target_is_categorical = True):\n",
        "    from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler, StringIndexerModel\n",
        "    from pyspark.ml import Pipeline\n",
        "\n",
        "    stages = []\n",
        "\n",
        "    for c in categorical_features:\n",
        "        stringIndexer = StringIndexer(inputCol = c, outputCol = c + '_Index')\n",
        "        encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[c + \"_classVec\"])\n",
        "        stages += [stringIndexer, encoder]\n",
        "        \n",
        "    if target_is_categorical:\n",
        "        label_stringIdx = StringIndexer(inputCol = target_label, outputCol = 'label')\n",
        "        stages += [label_stringIdx]\n",
        "\n",
        "    assemblerInputs = [c + \"_classVec\" for c in categorical_features] + numeric_features\n",
        "    assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "    stages += [assembler]\n",
        "\n",
        "    pipeline = Pipeline(stages = stages)\n",
        "\n",
        "    return pipeline\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFW7Fs8UQ7EQ",
        "colab_type": "text"
      },
      "source": [
        "### Read the bank dataset ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "l9EUwz1uQ7ET",
        "colab_type": "code",
        "colab": {},
        "outputId": "057498b2-7e34-40d2-ca9e-2ce2807eb1fc"
      },
      "source": [
        "filename = 'bank.csv'\n",
        "df = spark.read.csv(f'{datapath}/finance/{filename}', header = True, inferSchema = True)\n",
        "display(df)\n",
        "\n",
        "# Save a pointer to the raw data\n",
        "dfRawFile = df\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>deposit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>2343</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>1042</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>45</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>1467</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>technician</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>1270</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>1389</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>2476</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>579</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54</td>\n",
              "      <td>admin.</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>184</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>673</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>42</td>\n",
              "      <td>management</td>\n",
              "      <td>single</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>562</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>56</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>830</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>unknown</td>\n",
              "      <td>6</td>\n",
              "      <td>may</td>\n",
              "      <td>1201</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>60</td>\n",
              "      <td>retired</td>\n",
              "      <td>divorced</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>545</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>6</td>\n",
              "      <td>may</td>\n",
              "      <td>1030</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>37</td>\n",
              "      <td>technician</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>6</td>\n",
              "      <td>may</td>\n",
              "      <td>608</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>28</td>\n",
              "      <td>services</td>\n",
              "      <td>single</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>5090</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>6</td>\n",
              "      <td>may</td>\n",
              "      <td>1297</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age         job   marital  education default  balance housing loan  \\\n",
              "0   59      admin.   married  secondary      no     2343     yes   no   \n",
              "1   56      admin.   married  secondary      no       45      no   no   \n",
              "2   41  technician   married  secondary      no     1270     yes   no   \n",
              "3   55    services   married  secondary      no     2476     yes   no   \n",
              "4   54      admin.   married   tertiary      no      184      no   no   \n",
              "5   42  management    single   tertiary      no        0     yes  yes   \n",
              "6   56  management   married   tertiary      no      830     yes  yes   \n",
              "7   60     retired  divorced  secondary      no      545     yes   no   \n",
              "8   37  technician   married  secondary      no        1     yes   no   \n",
              "9   28    services    single  secondary      no     5090     yes   no   \n",
              "\n",
              "   contact  day month  duration  campaign  pdays  previous poutcome deposit  \n",
              "0  unknown    5   may      1042         1     -1         0  unknown     yes  \n",
              "1  unknown    5   may      1467         1     -1         0  unknown     yes  \n",
              "2  unknown    5   may      1389         1     -1         0  unknown     yes  \n",
              "3  unknown    5   may       579         1     -1         0  unknown     yes  \n",
              "4  unknown    5   may       673         2     -1         0  unknown     yes  \n",
              "5  unknown    5   may       562         2     -1         0  unknown     yes  \n",
              "6  unknown    6   may      1201         1     -1         0  unknown     yes  \n",
              "7  unknown    6   may      1030         1     -1         0  unknown     yes  \n",
              "8  unknown    6   may       608         1     -1         0  unknown     yes  \n",
              "9  unknown    6   may      1297         3     -1         0  unknown     yes  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2ARRZ1lzQ7Ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import OneHotEncoderEstimator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "start = timer()\n",
        "\n",
        "col = 'marital'\n",
        "m_indexer = StringIndexer(inputCol = col, outputCol = col+'_Index')\n",
        "x1 = m_indexer.fit(df).transform(df) #.select(col, col+'_Index')\n",
        "\n",
        "m_encoder = OneHotEncoderEstimator(inputCols=[col + '_Index'], outputCols=[col+'_Vector'])\n",
        "x2 = m_encoder.fit(x1).transform(x1).orderBy(col + '_Index')\n",
        "\n",
        "col = 'job'\n",
        "j_indexer = StringIndexer(inputCol = col, outputCol = col+'_Index')\n",
        "x3 = j_indexer.fit(x2).transform(x2)\n",
        "j_encoder = OneHotEncoderEstimator(inputCols=[col + '_Index'], outputCols=[col+'_Vector'])\n",
        "x4 = j_encoder.fit(x3).transform(x3)\n",
        "\n",
        "#display(x2.select('marital', 'marital_Index', 'marital_Vector'))\n",
        "end = timer()\n",
        "print('time to run', end - start)\n",
        "display(x2)\n",
        "\n",
        "start = timer()\n",
        "col = 'marital'\n",
        "m_indexer = StringIndexer(inputCol = col, outputCol = col+'_Index')\n",
        "m_encoder = OneHotEncoderEstimator(inputCols=[col + '_Index'], outputCols=[col+'_Vector'])\n",
        "#pipeline = Pipeline(stages = [m_indexer, m_encoder])\n",
        "\n",
        "col = 'job'\n",
        "j_indexer = StringIndexer(inputCol = col, outputCol = col+'_Index')\n",
        "j_encoder = OneHotEncoderEstimator(inputCols=[col + '_Index'], outputCols=[col+'_Vector'])\n",
        "\n",
        "v_encoder = VectorAssembler(inputCols = ['age','marital_Vector', 'job_Vector'], outputCol = 'features')\n",
        "pipeline = Pipeline(stages = [m_indexer, j_indexer, m_encoder, j_encoder, v_encoder])\n",
        "dfModel = pipeline.fit(df)\n",
        "#dfModel.save()\n",
        "dfML = dfModel.transform(df)\n",
        "end = timer()\n",
        "print('time to run', end - start)\n",
        "display(dfML)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzTSPPJ3Q7Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import OneHotEncoderEstimator\n",
        "col = 'marital'\n",
        "indexer = StringIndexer(inputCol = col, outputCol = col+'_Index')\n",
        "x1 = indexer.fit(df).transform(df) #.select(col, col+'_Index')\n",
        "\n",
        "encoder = OneHotEncoderEstimator(inputCols=[col + '_Index'], outputCols=[col+'_Vector'])\n",
        "x2 = encoder.fit(x1).transform(x1).orderBy(col + '_Index')\n",
        "display(x2.select('marital', 'marital_Index', 'marital_Vector'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GBDousIQ7El",
        "colab_type": "text"
      },
      "source": [
        "### Use the same categorical and numeric features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-ZomoupQ7Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's just keep a few fields to start with for simplicity\n",
        "numeric_features = ['age','balance', 'duration', 'pdays']\n",
        "categorical_features = ['job', 'marital', 'education', 'housing', 'loan', 'contact', 'campaign', 'poutcome', 'deposit']\n",
        "\n",
        "# numeric_features = ['balance', 'duration', 'age']\n",
        "# categorical_features = ['marital', 'education']\n",
        "target_label = 'default'\n",
        "\n",
        "\n",
        "df = dfRawFile.select(numeric_features + categorical_features + [target_label])\n",
        "display(df)\n",
        "print(df.take(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW2_THZsQ7Eu",
        "colab_type": "text"
      },
      "source": [
        "### Try this using the original helper vs. the Pipeline version to see if there is a time difference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stwhv7nCQ7Ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "start = timer()\n",
        "\n",
        "dfModel, dfML = MakeMLDataFramePipeline(df, categorical_features, numeric_features, target_label)\n",
        "#dfML = pyh.MakeMLDataFramePipeline(df, categorical_features, numeric_features, target_label)\n",
        "#dfML = pyh.MakeMLDataFrame(df, categorical_features, numeric_features, target_label)\n",
        "\n",
        "display(dfML)\n",
        "dfML.printSchema()\n",
        "labelCnt = dfML.groupBy('label').count()\n",
        "display(labelCnt)\n",
        "\n",
        "end = timer()\n",
        "print('time to run', end - start)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNeM9WLSQ7E_",
        "colab_type": "text"
      },
      "source": [
        "### Train and test as normal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FXs9zsbQ7FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = dfML.randomSplit([.7,.3], seed = 10)\n",
        "print (f'Training set row count {train.count()}')\n",
        "print (f'Testing set row count {test.count()}')\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qqXvpPhQ7FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n",
        "dtModel = dt.fit(train)\n",
        "print('DT Trained')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDrBdcgSQ7Fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtPredictions, dtLog = pyh.predict_and_evaluate(dtModel, test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "H1wRv-VKQ7Fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = dict(age=59, balance=2343, duration=1042, pdays=-1, job='admin.', marital='married', education='secondary', housing='yes', loan='no', contact='unknown', campaign=1, poutcome='unknown', deposit='yes')\n",
        "print(predict)\n",
        "predict = spark.createDataFrame(sc.parallelize([predict]))\n",
        "print(predict)\n",
        "predictML = dfModel.transform(predict)\n",
        "#x = dtModel.transform(predict)\n",
        "\n",
        "print(predictML.take(1))\n",
        "\n",
        "prediction = dtModel.transform(predictML).select('prediction')\n",
        "print(prediction.collect()[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TRuApNMQ7Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_bankdefault(transformModel, predictionModel, d): #age, balance, duration, pdays, job, marital, education, housing, loan, contact, campaign, poutcome, deposit):\n",
        "    newDF = spark.createDataFrame(sc.parallelize([d]))\n",
        "    predictML = transformModel.transform(newDF)\n",
        "    prediction = predictionModel.transform(predictML)\n",
        "    return (prediction.collect())[0][0]\n",
        "\n",
        "predict = dict(age=19, balance=2343, duration=1042, pdays=-1, job='admin.', marital='married', education='secondary', housing='yes', loan='no', contact='unknown', campaign=1, poutcome='unknown', deposit='yes')\n",
        "print (predict_bankdefault(dfModel, dtModel, predict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwhj2P_QQ7Fz",
        "colab_type": "text"
      },
      "source": [
        "### Pipelines and writing your own models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ISf2NoQ7F3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.pipeline import Estimator, Model, Pipeline, Transformer\n",
        "from pyspark.ml.param.shared import *\n",
        "from pyspark.sql.functions import avg, stddev_samp\n",
        "\n",
        "\n",
        "class myTransformer(Transformer):\n",
        "    pass\n",
        "\n",
        "class HasMean(Params):\n",
        "\n",
        "    mean = Param(Params._dummy(), \"mean\", \"mean\", \n",
        "        typeConverter=TypeConverters.toFloat)\n",
        "\n",
        "    def __init__(self):\n",
        "        super(HasMean, self).__init__()\n",
        "\n",
        "    def setMean(self, value):\n",
        "        return self._set(mean=value)\n",
        "\n",
        "    def getMean(self):\n",
        "        return self.getOrDefault(self.mean)\n",
        "    \n",
        "class HasStandardDeviation(Params):\n",
        "\n",
        "    stddev = Param(Params._dummy(), \"stddev\", \"stddev\", \n",
        "        typeConverter=TypeConverters.toFloat)\n",
        "\n",
        "    def __init__(self):\n",
        "        super(HasStandardDeviation, self).__init__()\n",
        "\n",
        "    def setStddev(self, value):\n",
        "        return self._set(stddev=value)\n",
        "\n",
        "    def getStddev(self):\n",
        "        return self.getOrDefault(self.stddev)\n",
        "\n",
        "class HasCenteredThreshold(Params):\n",
        "\n",
        "    centered_threshold = Param(Params._dummy(),\n",
        "            \"centered_threshold\", \"centered_threshold\",\n",
        "            typeConverter=TypeConverters.toFloat)\n",
        "\n",
        "    def __init__(self):\n",
        "        super(HasCenteredThreshold, self).__init__()\n",
        "\n",
        "    def setCenteredThreshold(self, value):\n",
        "        return self._set(centered_threshold=value)\n",
        "\n",
        "    def getCenteredThreshold(self):\n",
        "        return self.getOrDefault(self.centered_threshold)\n",
        "    \n",
        "class NormalDeviation(Estimator, HasInputCol, \n",
        "        HasPredictionCol, HasCenteredThreshold):\n",
        "\n",
        "    def _fit(self, dataset):\n",
        "        c = self.getInputCol()\n",
        "        mu, sigma = dataset.agg(avg(c), stddev_samp(c)).first()\n",
        "        return (NormalDeviationModel()\n",
        "            .setInputCol(c)\n",
        "            .setMean(mu)\n",
        "            .setStddev(sigma)\n",
        "            .setCenteredThreshold(self.getCenteredThreshold())\n",
        "            .setPredictionCol(self.getPredictionCol()))\n",
        "\n",
        "class NormalDeviationModel(Model, HasInputCol, HasPredictionCol,\n",
        "        HasMean, HasStandardDeviation, HasCenteredThreshold):\n",
        "\n",
        "    def _transform(self, dataset):\n",
        "        x = self.getInputCol()\n",
        "        y = self.getPredictionCol()\n",
        "        threshold = self.getCenteredThreshold()\n",
        "        mu = self.getMean()\n",
        "        sigma = self.getStddev()\n",
        "\n",
        "        return dataset.withColumn(y, (dataset[x] - mu) > threshold * sigma)\n",
        "\n",
        "df = sc.parallelize([(1, 2.0), (2, 3.0), (3, 0.0), (4, 99.0)]).toDF([\"id\", \"x\"])\n",
        "\n",
        "normal_deviation = NormalDeviation().setInputCol(\"x\").setCenteredThreshold(1.0)\n",
        "model  = Pipeline(stages=[normal_deviation]).fit(df)\n",
        "#print(normal_deviation.getMean())\n",
        "model.transform(df).show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zClZkv3Q7F-",
        "colab_type": "text"
      },
      "source": [
        "### PandasUDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdVMo_TeQ7GC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = spark.createDataFrame(pd.DataFrame(pd.Series(range(11)), columns=[\"x\"]))\n",
        "display(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il6beyitQ7GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dbl(x):\n",
        "    return x * 2\n",
        "\n",
        "nums1 = [1, 2, 3, 4]\n",
        "nums2 = []\n",
        "for n in nums1:\n",
        "    nums2.append(dbl(n)) \n",
        "\n",
        "print (nums1 * 2)\n",
        "\n",
        "import numpy as np\n",
        "nums3 = np.array([1, 2, 3, 4])\n",
        "nums4 = nums3 * 2\n",
        "\n",
        "print (nums3 * 2)\n",
        "\n",
        "\n",
        "print(nums3 - nums3.mean())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ibhsGkuQ7GR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "def func1(x):\n",
        "    return x + 1\n",
        "\n",
        "display(df.withColumn('func1', udf(func1, 'int')(df.x)))\n",
        "\n",
        "func1x = udf(func1, 'int')\n",
        "display(df.withColumn('func1x', func1x(df.x)))\n",
        "\n",
        "sqr = udf(lambda x : x * x , 'int') \n",
        "display(df.withColumn('x3', sqr(df.x)))\n",
        "\n",
        "@udf('int')\n",
        "def square(x):\n",
        "      return x * 2\n",
        "\n",
        "display(df.withColumn('x2', square(df.x)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10_DxWlGQ7GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! pip install pyarrow\n",
        "#import pyarrow\n",
        "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
        "#from pyspark.sql.types import LongType\n",
        "\n",
        "@pandas_udf('double', PandasUDFType.SCALAR)\n",
        "def psquare(x):\n",
        "      return x * x\n",
        "   \n",
        "#pandas_square = pandas_udf(psquare, returnType=LongType())\n",
        "\n",
        "df.withColumn('x3', psquare(df.x)).show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAbuLn5HQ7Gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}