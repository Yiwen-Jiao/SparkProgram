{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "rootpath = '/home/student/ROI/SparkProgram/'\n",
    "datapath = f'{rootpath}datasets/'\n",
    "sys.path.append(rootpath)\n",
    "import pyspark_helpers as pyh\n",
    "from pyspark_helpers import *\n",
    "sc, spark, conf = initspark()\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the bank dataset see if you can find the natural number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bank.csv'\n",
    "df = spark.read.csv(f'{datapath}/finance/{filename}', header = True, inferSchema = True)\n",
    "display(df)\n",
    "df.printSchema()\n",
    "dfRaw = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested features are\n",
    "numeric: 'age', 'balance','duration','pdays','previous'\n",
    "categorical_features: 'job','marital','education',      'housing','loan','campaign','deposit'\n",
    "target_label: None\n",
    "\n",
    "#### Hint:\n",
    "use helper function pyh.MakeMLDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'balance','duration','pdays','previous']\n",
    "categorical_features = ['job','marital','education','housing','loan','campaign','deposit']\n",
    "target_label = None\n",
    "\n",
    "dfML = pyh.MakeMLDataFrame(df, categorical_features, numeric_features, target_label, False)\n",
    "display(dfML)\n",
    "dfML.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an elbow plot\n",
    "Hint: Use the helper function pyh.plot_elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pyh.plot_elbow(dfML.select('features'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a cluster analysis with the suggested number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "CLUSTERS = 8\n",
    "kmeans = KMeans().setK(CLUSTERS).setSeed(1)\n",
    "model = kmeans.fit(dfML.select('features'))\n",
    "predictions = model.transform(dfML)\n",
    "centroids = model.clusterCenters()\n",
    "print(centroids)\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See if you can predict someone's age from the dataset\n",
    "suggested numeric features: 'balance','duration','pdays','previous'\n",
    "categorical features: 'job','marital','education','housing',\n",
    "'loan','campaign','deposit'\n",
    "target: 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(pyh)\n",
    "\n",
    "numeric_features = ['balance','duration','pdays','previous']\n",
    "categorical_features = ['job','marital','education','housing','loan','campaign','deposit']\n",
    "target_label = 'age'\n",
    "\n",
    "dfML = pyh.MakeMLDataFrame(dfRaw, categorical_features, numeric_features, target_label, False)\n",
    "display(dfML)\n",
    "dfML.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dfML.randomSplit([.7,.3], seed = 1000)\n",
    "print (f'Training set row count {train.count()}')\n",
    "print (f'Testing set row count {test.count()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='target', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lrModel = lr.fit(train)\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "print(\"Root Mean Squared Error: {}\\nR Squared (R2) {}\".format(lrModel.summary.rootMeanSquaredError, lrModel.summary.r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well it did some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrPredictions = lrModel.transform(test)\n",
    "display(lrPredictions.select(\"prediction\",\"target\",\"features\"), 30)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lrEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"target\",metricName=\"r2\")\n",
    "testResult = lrModel.evaluate(test)\n",
    "print(\"Root Mean Squared Error on Test set: {}\".format(testResult.rootMeanSquaredError))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
